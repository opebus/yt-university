import logging

from modal import Image, Secret

from yt_university.stub import stub

logger = logging.getLogger(__name__)

summarize_image = Image.debian_slim(python_version="3.12").pip_install(
    "exa_py", "openai"
)


# reference
# - https://www.reddit.com/r/ChatGPT/comments/11pd2um/the_best_prompt_for_summary_youtube/
def create_prompt(title: str, text: str) -> str:
    return f"""
        Given the transcript below:
        {text}

        For the video titled "{title}", write an in-depth analysis that both informs and engages readers. Your narrative should unfold with clarity and insight, reflecting the style of a Paul Graham essay.

        Return the essay in JSON with the following format:
        {{"tl;dr":"content","terminologies": {{"<Term 1>": "<Term 1 content>","<Term 2>": "<Term 2 content>",...}},"takeaways": "<takeaways content>","summary": {{"<Key Idea 1>": "<key idea 1 content>","<Key Idea 2>": "<key idea 2 content>",...}}}}

        Below are instructions for each section of the essay:

        # tl;dr

        Produce a TL;DR that captures the essential points in a concise and informative manner. It should be brief yet comprehensive, providing a clear snapshot of the video's content in a few sentences. This summary should enable someone who has not watched the video to understand the key points and takeaways quickly. This section should relate well to the rest of the content below.

        # Terminologies

        List and define key terminologies and acronyms used in the video. The definitions should be clear and tailored for readers unfamiliar with the specific jargon.

        # Takeaways

        - Conclude with bullet points outlining practical advice or steps derived from the video content.
        - These should connect directly to the insights discussed and emphasize their applicability and impact in real-world scenarios.

        # Summary

        Your summary should unfold as a detailed and engaging narrative essay, deeply exploring the content of the video. It is broken down into key ideas, each with its own paragraph. Each idea should be well-developed, providing context, explanation, and examples where necessary. The essay should be structured logically, with a clear flow of ideas and transitions between paragraphs. It should be long enough to cover the main points but concise enough to maintain the reader's interest.
    """


def json_to_markdown(data: str) -> str:
    import json

    data = json.loads(data)

    markdown = ""

    markdown += f"# tl;dr\n\n{data['tl;dr']}\n\n"

    markdown += "# Terminologies\n\n"
    for term, definition in data["terminologies"].items():
        markdown += f"1. {term}: {definition}\n\n"

    markdown += "# Takeaways\n\n"
    for takeaway in data["takeaways"]:
        markdown += f"- {takeaway}\n"

    markdown += "\n# Summary\n\n"
    for key_idea, content in data["summary"].items():
        markdown += f"## {key_idea}\n\n{content}\n\n"

    return markdown


@stub.function(
    image=summarize_image,
    secrets=[Secret.from_name("university")],
    container_idle_timeout=5,
    keep_warm=1,
)
def generate_summary(title: str, text: str):
    """
    Summarize the transcribed text using OpenAI's GPT model.
    """
    import os

    from openai import OpenAI

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": create_prompt(title, text)}],
            response_format={"type": "json_object"},
        )
        summary_json = response.choices[0].message.content.strip()
        print("summary_json", summary_json)
        summary = json_to_markdown(summary_json)
        return summary
    except Exception as e:
        logger.error(f"Error in summarizing transcription: {str(e)}")
        return "Failed to generate summary."


def extract_tldr(output_text: str) -> str:
    import re

    """

    Extracts the TL;DR section from the output text.

    Parameters:
        output_text (str): The complete output text generated by the language model.

    Returns:
        str: The extracted TL;DR section or an informative message if the section is not found.
    """
    # Pattern to capture text starting from TL;DR up to but not including the Intro heading
    pattern = r"# tl;dr\n\n(.*?)(?=\n\n# Intro)"

    # Using re.DOTALL to make '.' match any character including newline
    match = re.search(pattern, output_text, re.DOTALL)

    if match:
        return match.group(1).strip()  # Remove any leading/trailing whitespace
    else:
        return "TL;DR section not found."


CATEGORIES = [
    "Tutorials",
    "Technology",
    "Healthcare",
    "Business",
    "History",
    "Mathematics",
    "Engineering",
    "Languages",
    "Literature",
    "Art",
    "Music",
    "Programming",
    "Environment",
    "Politics",
    "Psychology",
    "Law",
    "Biology",
    "Astronomy",
    "Economics",
    "Sports",
    "Culture",
    "Philosophy",
    "Education",
    "Leadership",
    "Medicine",
]


def create_categorize_prompt(title, text):
    return f"""
        Your task is to categorize the following text into tags.

        Use the categories provided below to tag the text accordingly. You are only allowed to select one category.

        Return selection in a string format, without being quoted with casing as shown.

        {CATEGORIES}

        Title: {title}
        Text: {text}
    """


@stub.function(
    image=summarize_image,
    secrets=[Secret.from_name("university")],
    container_idle_timeout=5,
    keep_warm=1,
)
def categorize_text(title: str, text: str):
    import os

    from openai import OpenAI

    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    try:
        tldr_text = extract_tldr(text)
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "user", "content": create_categorize_prompt(title, tldr_text)}
            ],
        )
        category = response.choices[0].message.content.strip()
        return category.replace("'", "").replace('"', "")
    except Exception as e:
        logger.error(f"Error in categorizing transcription: {str(e)}")
        return "Failed to categorize summary."


@stub.function(
    image=summarize_image,
    secrets=[Secret.from_name("university")],
    container_idle_timeout=5,
    keep_warm=1,
)
def get_related_content(url: str):
    import os

    from exa_py import Exa

    exa = Exa(api_key=os.getenv("EXA_API_KEY"))

    result = exa.find_similar_and_contents(url, num_results=10, highlights=True)
    return result


@stub.local_entrypoint()
def main():
    import json

    from dotenv import load_dotenv

    load_dotenv()
    with open("./example.json") as f:
        data = json.load(f)

        category = categorize_text.local(data["title"], data["transcription"])
        print("Categorized as:", category)
